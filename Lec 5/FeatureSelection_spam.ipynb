{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spam Detection using Text Mining and Naive Bayes Classifier\n",
    "\n",
    "- Each SMS message can be a spam or a ham (legitimate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import useful libararies used for data management\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# load dataset 'Spam.csv', using 'python' as engine\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n",
    "dataset = pd.read_csv(\"Spam.csv\", encoding = \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi...I have to use R to find out the 90% confidence-interval for the sensitivityand specificity of the following diagnostic test:A particular diagnostic test for multiple sclerosis was conducted on 20 MSpatients and 20 healthy subjects, 6 MS patients were classified as healthyand 8 healthy subjects were classified as suffering from the MS.Furthermore, I need to find the number of MS patients required for asensitivity of 1%...Is there a simple R-command which can do that for me?I am completel...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Francesco Poli wrote:) On Sun, 15 Apr 2007 21:24:00 +0200 Arnoud Engelfriet wrote:) ) The sign [X] (hereafter \"the Mark\") is a trademark, rights to which) ) are held by [Y], representing [Z] if applicable (hereafter \"the) ) Mark Holder\").) ) Wait, the \"Mark Holder\" would be [Y], I think.I thought you used Y and Z for cases where Y is licensing Z'strademark (if Y is Z's subsidiary or authorized licensee for example).Then the trademark holder is Z but Y has certain rights to the mark.The \"if a...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephen Thorne wrote:) What I was thinking was possibly using the web browser and a local) light weight http server of some kind (SimpleHTTPServer or something)) that would serve ajaxy data to the web browser and integrate with) things like the journal. This way even if the Web activity with its) MozEmbed component dies via OOM, the backend store can still be) written (and the backend store can take SIGDANGER signals and cache) that data to disk).This is exactly what's being worked on.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi,I have this site that auto generates an index.html file every 15 minutes(it's a blog aggregator).I need that every time the file is generated, all the contents betweenthe lines(h4 class=\"post-title\")(ahref=\"http://domain.com/2006/08/bourne-shell.html\")Bourne Shell(/a)(/h4)and (p)(a href=\"http://domain.com/2006/08/bourne-shell.html\")S??b, 14 Abr2007 12:31:07(/a)(/p)to be deleted (including these two ones).I've tried several ways and googled but i can't do the trick.Any help would be apprec...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Author: metzeDate: 2007-04-16 08:20:13 +0000 (Mon, 16 Apr 2007)New Revision: 22249WebSVN: http://websvn.samba.org/cgi-bin/viewcvs.cgi?view=rev&amp;root=samba&amp;rev=22249Log:move tdb code to lib/tdb/ as in samba4metzeAdded: branches/SAMBA_3_0/source/lib/tdb/Removed: branches/SAMBA_3_0/source/tdb/Modified: branches/SAMBA_3_0/source/Makefile.in branches/SAMBA_3_0/source/configure.inChangeset:Modified: branches/SAMBA_3_0/source/Makefile.in===============================================================...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Text  \\\n",
       "0  Hi...I have to use R to find out the 90% confidence-interval for the sensitivityand specificity of the following diagnostic test:A particular diagnostic test for multiple sclerosis was conducted on 20 MSpatients and 20 healthy subjects, 6 MS patients were classified as healthyand 8 healthy subjects were classified as suffering from the MS.Furthermore, I need to find the number of MS patients required for asensitivity of 1%...Is there a simple R-command which can do that for me?I am completel...   \n",
       "1  Francesco Poli wrote:) On Sun, 15 Apr 2007 21:24:00 +0200 Arnoud Engelfriet wrote:) ) The sign [X] (hereafter \"the Mark\") is a trademark, rights to which) ) are held by [Y], representing [Z] if applicable (hereafter \"the) ) Mark Holder\").) ) Wait, the \"Mark Holder\" would be [Y], I think.I thought you used Y and Z for cases where Y is licensing Z'strademark (if Y is Z's subsidiary or authorized licensee for example).Then the trademark holder is Z but Y has certain rights to the mark.The \"if a...   \n",
       "2           Stephen Thorne wrote:) What I was thinking was possibly using the web browser and a local) light weight http server of some kind (SimpleHTTPServer or something)) that would serve ajaxy data to the web browser and integrate with) things like the journal. This way even if the Web activity with its) MozEmbed component dies via OOM, the backend store can still be) written (and the backend store can take SIGDANGER signals and cache) that data to disk).This is exactly what's being worked on.   \n",
       "3  Hi,I have this site that auto generates an index.html file every 15 minutes(it's a blog aggregator).I need that every time the file is generated, all the contents betweenthe lines(h4 class=\"post-title\")(ahref=\"http://domain.com/2006/08/bourne-shell.html\")Bourne Shell(/a)(/h4)and (p)(a href=\"http://domain.com/2006/08/bourne-shell.html\")S??b, 14 Abr2007 12:31:07(/a)(/p)to be deleted (including these two ones).I've tried several ways and googled but i can't do the trick.Any help would be apprec...   \n",
       "4  Author: metzeDate: 2007-04-16 08:20:13 +0000 (Mon, 16 Apr 2007)New Revision: 22249WebSVN: http://websvn.samba.org/cgi-bin/viewcvs.cgi?view=rev&root=samba&rev=22249Log:move tdb code to lib/tdb/ as in samba4metzeAdded: branches/SAMBA_3_0/source/lib/tdb/Removed: branches/SAMBA_3_0/source/tdb/Modified: branches/SAMBA_3_0/source/Makefile.in branches/SAMBA_3_0/source/configure.inChangeset:Modified: branches/SAMBA_3_0/source/Makefile.in===============================================================...   \n",
       "\n",
       "  Class  \n",
       "0   ham  \n",
       "1   ham  \n",
       "2   ham  \n",
       "3   ham  \n",
       "4   ham  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.set_option.html\n",
    "# set max_colwidth 500\n",
    "pd.set_option('display.max_colwidth', 500)  \n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     4864\n",
       "spam    3246\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the 'label' column into a numeric variable; 'ham' as 0, 'spam' as 1\n",
    "# Alternatively, you can do one-hot-encoding, and drop the attribute Class_ham.\n",
    "dataset['Label'] = dataset['Class'].map({'ham':0, 'spam':1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Class</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hi...I have to use R to find out the 90% confidence-interval for the sensitivityand specificity of the following diagnostic test:A particular diagnostic test for multiple sclerosis was conducted on 20 MSpatients and 20 healthy subjects, 6 MS patients were classified as healthyand 8 healthy subjects were classified as suffering from the MS.Furthermore, I need to find the number of MS patients required for asensitivity of 1%...Is there a simple R-command which can do that for me?I am completel...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Francesco Poli wrote:) On Sun, 15 Apr 2007 21:24:00 +0200 Arnoud Engelfriet wrote:) ) The sign [X] (hereafter \"the Mark\") is a trademark, rights to which) ) are held by [Y], representing [Z] if applicable (hereafter \"the) ) Mark Holder\").) ) Wait, the \"Mark Holder\" would be [Y], I think.I thought you used Y and Z for cases where Y is licensing Z'strademark (if Y is Z's subsidiary or authorized licensee for example).Then the trademark holder is Z but Y has certain rights to the mark.The \"if a...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stephen Thorne wrote:) What I was thinking was possibly using the web browser and a local) light weight http server of some kind (SimpleHTTPServer or something)) that would serve ajaxy data to the web browser and integrate with) things like the journal. This way even if the Web activity with its) MozEmbed component dies via OOM, the backend store can still be) written (and the backend store can take SIGDANGER signals and cache) that data to disk).This is exactly what's being worked on.</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hi,I have this site that auto generates an index.html file every 15 minutes(it's a blog aggregator).I need that every time the file is generated, all the contents betweenthe lines(h4 class=\"post-title\")(ahref=\"http://domain.com/2006/08/bourne-shell.html\")Bourne Shell(/a)(/h4)and (p)(a href=\"http://domain.com/2006/08/bourne-shell.html\")S??b, 14 Abr2007 12:31:07(/a)(/p)to be deleted (including these two ones).I've tried several ways and googled but i can't do the trick.Any help would be apprec...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Author: metzeDate: 2007-04-16 08:20:13 +0000 (Mon, 16 Apr 2007)New Revision: 22249WebSVN: http://websvn.samba.org/cgi-bin/viewcvs.cgi?view=rev&amp;root=samba&amp;rev=22249Log:move tdb code to lib/tdb/ as in samba4metzeAdded: branches/SAMBA_3_0/source/lib/tdb/Removed: branches/SAMBA_3_0/source/tdb/Modified: branches/SAMBA_3_0/source/Makefile.in branches/SAMBA_3_0/source/configure.inChangeset:Modified: branches/SAMBA_3_0/source/Makefile.in===============================================================...</td>\n",
       "      <td>ham</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Text  \\\n",
       "0  Hi...I have to use R to find out the 90% confidence-interval for the sensitivityand specificity of the following diagnostic test:A particular diagnostic test for multiple sclerosis was conducted on 20 MSpatients and 20 healthy subjects, 6 MS patients were classified as healthyand 8 healthy subjects were classified as suffering from the MS.Furthermore, I need to find the number of MS patients required for asensitivity of 1%...Is there a simple R-command which can do that for me?I am completel...   \n",
       "1  Francesco Poli wrote:) On Sun, 15 Apr 2007 21:24:00 +0200 Arnoud Engelfriet wrote:) ) The sign [X] (hereafter \"the Mark\") is a trademark, rights to which) ) are held by [Y], representing [Z] if applicable (hereafter \"the) ) Mark Holder\").) ) Wait, the \"Mark Holder\" would be [Y], I think.I thought you used Y and Z for cases where Y is licensing Z'strademark (if Y is Z's subsidiary or authorized licensee for example).Then the trademark holder is Z but Y has certain rights to the mark.The \"if a...   \n",
       "2           Stephen Thorne wrote:) What I was thinking was possibly using the web browser and a local) light weight http server of some kind (SimpleHTTPServer or something)) that would serve ajaxy data to the web browser and integrate with) things like the journal. This way even if the Web activity with its) MozEmbed component dies via OOM, the backend store can still be) written (and the backend store can take SIGDANGER signals and cache) that data to disk).This is exactly what's being worked on.   \n",
       "3  Hi,I have this site that auto generates an index.html file every 15 minutes(it's a blog aggregator).I need that every time the file is generated, all the contents betweenthe lines(h4 class=\"post-title\")(ahref=\"http://domain.com/2006/08/bourne-shell.html\")Bourne Shell(/a)(/h4)and (p)(a href=\"http://domain.com/2006/08/bourne-shell.html\")S??b, 14 Abr2007 12:31:07(/a)(/p)to be deleted (including these two ones).I've tried several ways and googled but i can't do the trick.Any help would be apprec...   \n",
       "4  Author: metzeDate: 2007-04-16 08:20:13 +0000 (Mon, 16 Apr 2007)New Revision: 22249WebSVN: http://websvn.samba.org/cgi-bin/viewcvs.cgi?view=rev&root=samba&rev=22249Log:move tdb code to lib/tdb/ as in samba4metzeAdded: branches/SAMBA_3_0/source/lib/tdb/Removed: branches/SAMBA_3_0/source/tdb/Modified: branches/SAMBA_3_0/source/Makefile.in branches/SAMBA_3_0/source/configure.inChangeset:Modified: branches/SAMBA_3_0/source/Makefile.in===============================================================...   \n",
       "\n",
       "  Class  Label  \n",
       "0   ham      0  \n",
       "1   ham      0  \n",
       "2   ham      0  \n",
       "3   ham      0  \n",
       "4   ham      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's define X and y \n",
    "\n",
    "X = dataset['Text']\n",
    "y = dataset['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8110,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the dimension of the X\n",
    "#https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's do train/test split on the X and y data (70% train, 30% test)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3 , random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5677,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the dimension of X_train\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2433,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the dimension of X_test\n",
    "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.ndarray.shape.html\n",
    "\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3393\n",
       "1    2284\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the number of 'ham' and 'spam' in the training set\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.value_counts.html\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Now we are ready to vectorize the data\n",
    "# first, instantiate the vectorizer\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "# When building the vocabulary ignore terms that have a document frequency strictly lower than the min_df (proportion), or higher than max_df\n",
    "vectorizer = CountVectorizer(encoding='utf-8',stop_words='english',min_df=0.02, max_df=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO\n",
    "- Please try TfidfVectorizer later to see the model performance (https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
    "- You need to use \"from sklearn.feature_extraction.text import TfidfVectorizer\" to import the TfidfVectorizer first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the vocabulary dictionary and return term-document matrix.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform\n",
    "X_train_vec = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000', '00our', '00proposition', '00we', '01', '02',\n",
       "       '0200', '03', '04', '05', '06', '07', '08', '09', '0nline', '10',\n",
       "       '100', '11', '12', '128', '129', '13', '14', '149', '149ableton',\n",
       "       '15', '16', '17', '18', '185technologies', '19', '1imited', '1o',\n",
       "       '20', '2006', '2007', '21', '22', '23', '24', '2441', '2442',\n",
       "       '2480', '25', '26', '27', '28', '29', '2http', '30', '31', '319',\n",
       "       '32', '33', '34', '35', '36', '369', '37', '38', '39', '399', '40',\n",
       "       '40speedy', '41', '42', '44', '449', '45', '47', '48', '49',\n",
       "       '49adobe', '49http', '50', '500', '56', '59', '60', '69adobe',\n",
       "       '75', '79', '80', '819', '89', '899', '90', '95', '95you',\n",
       "       '95your', '99', '______________________________________________',\n",
       "       '______________________________________________r', 'able', 'ac',\n",
       "       'access', 'account', 'accurate', 'acrobat', 'action', 'actually',\n",
       "       'add', 'added', 'additional', 'address', 'adobe', 'advance',\n",
       "       'advancedsolution', 'advertisement', 'advisor', 'affiliates',\n",
       "       'alerttmxotrimax', 'allow', 'alternative', 'analyst', 'andrew',\n",
       "       'andshould', 'answer', 'applied', 'applying', 'apr', 'april',\n",
       "       'archive', 'arenegotiating', 'argument', 'ask', 'atches', 'author',\n",
       "       'autocad', 'autodesk', 'availability', 'available', 'away', 'bad',\n",
       "       'banker', 'base', 'based', 'begin', 'beginners', 'behalf',\n",
       "       'believe', 'benefit', 'best', 'better', 'big', 'bin', 'bit',\n",
       "       'borland', 'bounces', 'box', 'bpl', 'braille', 'branch',\n",
       "       'branches', 'broadband', 'broker', 'brokerdealer', 'bug', 'build',\n",
       "       'business', 'buy', 'ca', 'called', 'care', 'case', 'cash', 'cc',\n",
       "       'cchangeset', 'cd', 'cgi', 'ch', 'change', 'changes', 'check',\n",
       "       'cheers', 'choice', 'class', 'clear', 'click', 'client', 'close',\n",
       "       'code', 'column', 'com', 'come', 'comes', 'command', 'commands',\n",
       "       'comment', 'commented', 'comments', 'common', 'communication',\n",
       "       'company', 'complete', 'computer', 'confidential', 'config',\n",
       "       'considered', 'consult', 'contact', 'contain', 'contained',\n",
       "       'containsforward', 'content', 'control', 'copy', 'copyright',\n",
       "       'corel', 'correct', 'cost', 'course', 'create', 'created',\n",
       "       'creative', 'cs', 'cs2', 'current', 'currently', 'daily', 'data',\n",
       "       'date', 'day', 'days', 'deal', 'dear', 'debian', 'decrease',\n",
       "       'default', 'defined', 'deleted', 'deliver', 'details', 'did',\n",
       "       'didn', 'difference', 'different', 'directors', 'directory', 'dis',\n",
       "       'discounts', 'discreet', 'discrete', 'discussed', 'does', 'doesn',\n",
       "       'doing', 'domain', 'don', 'download', 'downloaded', 'drive',\n",
       "       'drugs', 'dvd', 'easy', 'editionregular', 'edu', 'effects',\n",
       "       'efficient', 'electronic', 'email', 'ement', 'employees',\n",
       "       'en1argment', 'encryptedhigh', 'end', 'enhan', 'enterprise',\n",
       "       'environment', 'error', 'errors', 'essential', 'ethz', 'event',\n",
       "       'exactly', 'example', 'experience', 'factor', 'fail', 'failed',\n",
       "       'false', 'far', 'fast', 'favorite', 'fax', 'fedex', 'feel', 'file',\n",
       "       'files', 'fine', 'fit', 'fix', 'fixed', 'follow', 'following',\n",
       "       'form', 'format', 'frame', 'free', 'fri', 'friday', 'function',\n",
       "       'functions', 'future', 'general', 'generic', 'getting', 'given',\n",
       "       'gives', 'global', 'gmail', 'gnu', 'going', 'good', 'got',\n",
       "       'grafix', 'great', 'grid', 'group', 'guaranteed', 'guess', 'guide',\n",
       "       'hard', 'hash', 'haven', 'having', 'header', 'health', 'hello',\n",
       "       'help', 'helpplease', 'helps', 'hes', 'hi', 'high', 'hk', 'home',\n",
       "       'hope', 'host', 'html', 'https', 'id', 'idea', 'illustrator',\n",
       "       'important', 'include', 'including', 'inclusive', 'independent',\n",
       "       'index', 'individual', 'info', 'information',\n",
       "       'informationbelieved', 'install', 'installed', 'instant',\n",
       "       'instantly', 'instead', 'int', 'intend', 'internet', 'introducing',\n",
       "       'investment', 'involve', 'isn', 'issue', 'items', 'john', 'just',\n",
       "       'key', 'kind', 'know', 'laptop', 'large', 'later', 'latest', 'law',\n",
       "       'learn', 'leave', 'legal', 'length', 'let', 'level', 'lib',\n",
       "       'library', 'license', 'licensed', 'life', 'like', 'limited',\n",
       "       'line', 'lines', 'link', 'linux', 'list', 'listhttps', 'listinfo',\n",
       "       'lists', 'listspeakup', 'little', 'live', 'll', 'local', 'log',\n",
       "       'long', 'longer', 'look', 'looking', 'looks', 'loop', 'lose',\n",
       "       'lot', 'lover', 'low', 'mac', 'machine', 'macromedia', 'mail',\n",
       "       'mailing', 'mailman', 'mailto', 'main', 'make', 'maker', 'makes',\n",
       "       'making', 'male', 'man', 'manner', 'manuals', 'manufacturers',\n",
       "       'market', 'material', 'math', 'matrix', 'matter', 'maybe',\n",
       "       'maybuy', 'mean', 'means', 'meds', 'member', 'memory', 'men',\n",
       "       'mentioned', 'message', 'messages', 'method', 'methods',\n",
       "       'microsoft', 'millions', 'minimal', 'missing', 'model', 'modified',\n",
       "       'module', 'moment', 'mon', 'monday', 'money', 'month', 'ms',\n",
       "       'names', 'nearfuture', 'need', 'needed', 'needs', 'net', 'network',\n",
       "       'new', 'newest', 'news', 'nice', 'nick', 'night',\n",
       "       'no_prescripti0n_needed', 'non', 'note', 'null', 'number',\n",
       "       'object', 'oem', 'offer', 'offering', 'offers', 'office',\n",
       "       'officers', 'ok', 'old', 'online', 'open', 'opinion', 'option',\n",
       "       'order', 'org', 'orgfor', 'orghttp', 'original', 'orprofit', 'otc',\n",
       "       'ounts', 'output', 'package', 'packages', 'packing', 'page',\n",
       "       'parrot', 'particular', 'parties', 'pat', 'patch', 'path', 'pay',\n",
       "       'people', 'perl', 'phone', 'photoshop', 'php', 'pi11', 'pl',\n",
       "       'place', 'plain', 'plot', 'pm', 'pnis', 'point', 'points',\n",
       "       'possible', 'post', 'posting', 'power', 'pr0', 'premiere',\n",
       "       'premium', 'prepared', 'pretty', 'price', 'prices', 'print', 'pro',\n",
       "       'probably', 'problem', 'problems', 'process', 'product',\n",
       "       'products', 'producttestpanel', 'professional',\n",
       "       'professionalmarket', 'profit', 'program', 'project', 'property',\n",
       "       'propose', 'provide', 'providers', 'public', 'purchase',\n",
       "       'purchasingor', 'quality', 'question', 'questions', 'quickerand',\n",
       "       'quite', 'rank', 'read', 'reading', 'ready', 'real', 'really',\n",
       "       'reason', 'receive', 'received', 'regards', 'release', 'reliable',\n",
       "       'remove', 'replace', 'reply', 'report', 'reproducible', 'request',\n",
       "       'required', 'research', 'reserved', 'response', 'result',\n",
       "       'results', 'return', 'rev', 'reviews', 'revision', 'revno', 'rice',\n",
       "       'right', 'rights', 'rise', 'risks', 'road', 'roof', 'root', 'run',\n",
       "       'running', 'rx', 'safe', 'safer', 'safest', 'said', 'samba',\n",
       "       'samba_3_0', 'samba_4_0', 'sat', 'save', 'say', 'says', 'script',\n",
       "       'search', 'second', 'section', 'sector', 'securities', 'seen',\n",
       "       'self', 'sell', 'selling', 'send', 'sent', 'server', 'service',\n",
       "       'set', 'share', 'shares', 'shipping', 'short', 'signed', 'similar',\n",
       "       'simple', 'simply', 'single', 'site', 'situation', 'size', 'small',\n",
       "       'software', 'solution', 'sorry', 'sort', 'source', 'south', 'sp2',\n",
       "       'special', 'specific', 'speed', 'speedy', 'standard', 'start',\n",
       "       'started', 'stat', 'state', 'statements', 'states', 'statistics',\n",
       "       'stats', 'status', 'step', 'stop', 'store', 'street', 'string',\n",
       "       'studio', 'stuff', 'sub', 'subject', 'suite', 'sun', 'support',\n",
       "       'sure', 'sym', 'symmetrical', 't0', 't1sales', 't2', 't3best',\n",
       "       't4', 't6', 'table', 'target', 'team', 'technologies', 'tell',\n",
       "       'term', 'terms', 'test', 'tests', 'text', 'thank', 'thanks',\n",
       "       'thay', 'theirsize', 'thing', 'things', 'think', 'thought',\n",
       "       'throw', 'thu', 'thursday', 'time', 'times', 'tmxo', 'today',\n",
       "       'tools', 'trackable', 'trade', 'transmission', 'tried', 'true',\n",
       "       'try', 'trying', 'tue', 'type', 'uk', 'ultimate', 'ultimateretail',\n",
       "       'uncertainties', 'understand', 'underwriter', 'unhappy', 'united',\n",
       "       'university', 'unless', 'unreal', 'unsubscribe', 'url', 'use',\n",
       "       'used', 'useful', 'user', 'users', 'uses', 'using', 'usr', 'utc',\n",
       "       'uwaterloo', 'uwo', 'value', 'values', 'variable', 'variables',\n",
       "       'various', 've', 'vector', 'version', 'video', 'view', 'viewcvs',\n",
       "       'viewed', 'visit', 'vista', 'voice', 'want', 'wanted', 'warning',\n",
       "       'watch', 'watching', 'way', 'web', 'website', 'websvn', 'wed',\n",
       "       'week', 'windows', 'wish', 'women', 'won', 'work', 'working',\n",
       "       'works', 'world', 'write', 'writes', 'wrong', 'wrote', 'www', 'x3',\n",
       "       'xp', 'yahoo', 'year', 'years', 'yes', 'youcould'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the terms\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.get_feature_names\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 784)\t3\n",
      "  (0, 258)\t1\n",
      "  (0, 246)\t1\n",
      "  (0, 441)\t1\n",
      "  (0, 305)\t3\n",
      "  (0, 704)\t1\n",
      "  (0, 348)\t2\n",
      "  (0, 584)\t2\n",
      "  (0, 544)\t1\n",
      "  (0, 388)\t2\n",
      "  (0, 183)\t4\n",
      "  (0, 347)\t1\n",
      "  (0, 428)\t1\n",
      "  (0, 577)\t1\n",
      "  (0, 699)\t1\n",
      "  (0, 734)\t1\n",
      "  (0, 262)\t1\n",
      "  (0, 228)\t2\n",
      "  (0, 382)\t1\n",
      "  (0, 400)\t1\n",
      "  (0, 497)\t1\n",
      "  (1, 39)\t1\n",
      "  (1, 37)\t1\n",
      "  (1, 638)\t2\n",
      "  (1, 754)\t2\n",
      "  :\t:\n",
      "  (5676, 758)\t1\n",
      "  (5676, 447)\t1\n",
      "  (5676, 125)\t1\n",
      "  (5676, 167)\t1\n",
      "  (5676, 539)\t1\n",
      "  (5676, 110)\t1\n",
      "  (5676, 466)\t1\n",
      "  (5676, 575)\t1\n",
      "  (5676, 511)\t1\n",
      "  (5676, 112)\t1\n",
      "  (5676, 489)\t1\n",
      "  (5676, 239)\t1\n",
      "  (5676, 264)\t1\n",
      "  (5676, 440)\t1\n",
      "  (5676, 634)\t2\n",
      "  (5676, 245)\t1\n",
      "  (5676, 362)\t1\n",
      "  (5676, 626)\t1\n",
      "  (5676, 501)\t1\n",
      "  (5676, 275)\t1\n",
      "  (5676, 599)\t1\n",
      "  (5676, 229)\t1\n",
      "  (5676, 582)\t1\n",
      "  (5676, 747)\t1\n",
      "  (5676, 680)\t1\n"
     ]
    }
   ],
   "source": [
    "print(X_train_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 23)\t1\n",
      "  (0, 36)\t1\n",
      "  (0, 37)\t1\n",
      "  (0, 51)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 71)\t2\n",
      "  (0, 89)\t3\n",
      "  (0, 93)\t2\n",
      "  (0, 122)\t1\n",
      "  (0, 161)\t1\n",
      "  (0, 172)\t6\n",
      "  (0, 176)\t1\n",
      "  (0, 179)\t1\n",
      "  (0, 183)\t2\n",
      "  (0, 191)\t2\n",
      "  (0, 204)\t2\n",
      "  (0, 227)\t1\n",
      "  (0, 251)\t1\n",
      "  (0, 252)\t1\n",
      "  (0, 274)\t6\n",
      "  (0, 286)\t1\n",
      "  (0, 290)\t2\n",
      "  (0, 301)\t1\n",
      "  (0, 323)\t6\n",
      "  (0, 331)\t6\n",
      "  :\t:\n",
      "  (2432, 27)\t1\n",
      "  (2432, 32)\t4\n",
      "  (2432, 35)\t1\n",
      "  (2432, 37)\t4\n",
      "  (2432, 48)\t1\n",
      "  (2432, 49)\t1\n",
      "  (2432, 51)\t1\n",
      "  (2432, 52)\t4\n",
      "  (2432, 54)\t3\n",
      "  (2432, 55)\t3\n",
      "  (2432, 56)\t1\n",
      "  (2432, 57)\t2\n",
      "  (2432, 60)\t1\n",
      "  (2432, 61)\t1\n",
      "  (2432, 122)\t2\n",
      "  (2432, 160)\t7\n",
      "  (2432, 338)\t2\n",
      "  (2432, 491)\t1\n",
      "  (2432, 497)\t1\n",
      "  (2432, 611)\t4\n",
      "  (2432, 612)\t2\n",
      "  (2432, 666)\t2\n",
      "  (2432, 721)\t1\n",
      "  (2432, 735)\t1\n",
      "  (2432, 771)\t1\n"
     ]
    }
   ],
   "source": [
    "# Now let's transform the test data without fitting (fit only on training)! \n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.transform\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "print(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5677, 793)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Multinomial Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a Multinomial Naive Bayes Classifier, which is frequently used in Tf-idf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "mnb = MultinomialNB()\n",
    "# train the model using training set \n",
    "mnb.fit(X_train_vec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>-3.702794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>-4.342634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-4.403574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-4.556449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>-4.811341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>php</th>\n",
       "      <td>-4.833474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suite</th>\n",
       "      <td>-4.885449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>-4.887933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft</th>\n",
       "      <td>-4.909304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>-4.914400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-4.983119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>-5.068764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac</th>\n",
       "      <td>-5.119194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acrobat</th>\n",
       "      <td>-5.133401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>-5.192338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>windows</th>\n",
       "      <td>-5.195717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>-5.224903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>-5.235411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliver</th>\n",
       "      <td>-5.276747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>said</th>\n",
       "      <td>-5.280423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investment</th>\n",
       "      <td>-5.289674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>-5.293399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>-5.310332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>-5.312232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>-5.339208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broker</th>\n",
       "      <td>-5.341163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shares</th>\n",
       "      <td>-5.343122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broadband</th>\n",
       "      <td>-5.352974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offers</th>\n",
       "      <td>-5.370957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>-5.412115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>home</th>\n",
       "      <td>-5.424800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save</th>\n",
       "      <td>-5.461641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay</th>\n",
       "      <td>-5.468285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative</th>\n",
       "      <td>-5.493033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pro</th>\n",
       "      <td>-5.511425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>available</th>\n",
       "      <td>-5.527799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-5.554085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-5.558940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>download</th>\n",
       "      <td>-5.576118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macromedia</th>\n",
       "      <td>-5.578596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>-5.586068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-5.603723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instantly</th>\n",
       "      <td>-5.608825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vista</th>\n",
       "      <td>-5.611386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>-5.616527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enterprise</th>\n",
       "      <td>-5.619108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>-5.621695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>just</th>\n",
       "      <td>-5.621695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95your</th>\n",
       "      <td>-5.629498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>need</th>\n",
       "      <td>-5.634733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Log Probability\n",
       "com                 -3.702794\n",
       "adobe               -4.342634\n",
       "79                  -4.403574\n",
       "price               -4.556449\n",
       "software            -4.811341\n",
       "php                 -4.833474\n",
       "suite               -4.885449\n",
       "time                -4.887933\n",
       "microsoft           -4.909304\n",
       "2007                -4.914400\n",
       "59                  -4.983119\n",
       "office              -5.068764\n",
       "mac                 -5.119194\n",
       "acrobat             -5.133401\n",
       "size                -5.192338\n",
       "windows             -5.195717\n",
       "availability        -5.224903\n",
       "use                 -5.235411\n",
       "deliver             -5.276747\n",
       "said                -5.280423\n",
       "investment          -5.289674\n",
       "money               -5.293399\n",
       "opinion             -5.310332\n",
       "power               -5.312232\n",
       "www                 -5.339208\n",
       "broker              -5.341163\n",
       "shares              -5.343122\n",
       "broadband           -5.352974\n",
       "offers              -5.370957\n",
       "offer               -5.412115\n",
       "home                -5.424800\n",
       "save                -5.461641\n",
       "pay                 -5.468285\n",
       "creative            -5.493033\n",
       "pro                 -5.511425\n",
       "available           -5.527799\n",
       "49                  -5.554085\n",
       "like                -5.558940\n",
       "download            -5.576118\n",
       "macromedia          -5.578596\n",
       "drive               -5.586068\n",
       "80                  -5.603723\n",
       "instantly           -5.608825\n",
       "vista               -5.611386\n",
       "reviews             -5.616527\n",
       "enterprise          -5.619108\n",
       "05                  -5.621695\n",
       "just                -5.621695\n",
       "95your              -5.629498\n",
       "need                -5.634733"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empirical log probability of features given a class 1 (spam)\n",
    "coeff_df = pd.DataFrame(mnb.feature_log_prob_[1,:].flatten(), [vectorizer.get_feature_names_out()], columns=['Log Probability'])  \n",
    "coeff_df = coeff_df.sort_values(by=['Log Probability'], ascending=False)\n",
    "\n",
    "# display the 50 most informative features (indicate spam)\n",
    "coeff_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class prediction for test set\n",
    "# y_pred_class is the binary label\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict\n",
    "y_pred_class = mnb.predict(X_test_vec)\n",
    "\n",
    "# y_pred_prob is the probability estimate\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict_proba\n",
    "y_pred_prob = mnb.predict_proba(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9445129469790382\n",
      "Confusion Matrix: [[1464    7]\n",
      " [ 128  834]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      1471\n",
      "           1       0.99      0.87      0.93       962\n",
      "\n",
      "    accuracy                           0.94      2433\n",
      "   macro avg       0.96      0.93      0.94      2433\n",
      "weighted avg       0.95      0.94      0.94      2433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import libararies for evaluation measures\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_class, normalize=True, sample_weight=None))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_pred_class))\n",
    "print(\"Classification Report:\",classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "selectkbest = SelectKBest(chi2, k=400)\n",
    "selectkbest.fit(X_train_vec, y_train)\n",
    "X_train_vec2 = selectkbest.transform(X_train_vec)\n",
    "X_test_vec2 = selectkbest.transform(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   2,   3,   4,   5,   6,   7,  10,  13,  14,  15,  16,  17,\n",
       "        19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,  30,  31,\n",
       "        32,  33,  34,  35,  37,  38,  39,  40,  41,  42,  43,  44,  46,\n",
       "        48,  50,  51,  53,  54,  59,  63,  65,  68,  69,  72,  73,  74,\n",
       "        75,  79,  81,  83,  84,  85,  86,  87,  90,  91,  92,  93,  94,\n",
       "        97,  99, 100, 105, 107, 109, 110, 111, 112, 113, 115, 116, 118,\n",
       "       121, 122, 123, 125, 128, 129, 130, 131, 132, 136, 140, 143, 147,\n",
       "       149, 150, 152, 153, 155, 156, 157, 158, 160, 167, 171, 172, 177,\n",
       "       178, 183, 185, 189, 191, 193, 194, 199, 200, 201, 204, 205, 210,\n",
       "       216, 217, 218, 221, 222, 228, 229, 230, 232, 233, 238, 239, 240,\n",
       "       241, 242, 243, 244, 245, 247, 250, 251, 253, 255, 257, 258, 260,\n",
       "       261, 263, 264, 265, 266, 268, 269, 271, 274, 277, 281, 282, 284,\n",
       "       287, 289, 290, 293, 296, 298, 299, 303, 312, 317, 321, 323, 329,\n",
       "       331, 332, 334, 335, 337, 341, 342, 343, 345, 347, 349, 355, 356,\n",
       "       358, 359, 361, 362, 364, 365, 366, 368, 381, 383, 386, 387, 388,\n",
       "       389, 391, 396, 397, 398, 399, 400, 406, 413, 415, 417, 419, 420,\n",
       "       421, 422, 423, 425, 426, 429, 431, 432, 433, 435, 436, 437, 440,\n",
       "       441, 443, 445, 446, 447, 448, 450, 452, 453, 454, 456, 457, 458,\n",
       "       462, 466, 472, 473, 474, 476, 478, 481, 483, 484, 485, 486, 487,\n",
       "       488, 489, 493, 494, 497, 501, 502, 503, 505, 506, 507, 509, 511,\n",
       "       512, 515, 517, 519, 520, 521, 522, 525, 526, 527, 528, 532, 533,\n",
       "       534, 535, 536, 537, 539, 541, 542, 544, 547, 549, 550, 551, 552,\n",
       "       554, 556, 557, 558, 559, 561, 565, 567, 568, 578, 580, 583, 584,\n",
       "       589, 591, 592, 593, 594, 596, 599, 600, 602, 603, 604, 605, 606,\n",
       "       608, 609, 611, 612, 613, 615, 618, 622, 623, 625, 626, 627, 630,\n",
       "       632, 634, 635, 643, 644, 646, 650, 652, 653, 655, 660, 662, 666,\n",
       "       671, 672, 675, 676, 681, 682, 683, 685, 686, 687, 691, 695, 696,\n",
       "       697, 699, 700, 701, 704, 706, 711, 714, 716, 717, 718, 720, 722,\n",
       "       724, 725, 726, 728, 729, 733, 734, 736, 737, 742, 743, 744, 745,\n",
       "       746, 748, 749, 750, 752, 754, 756, 757, 758, 760, 761, 762, 766,\n",
       "       767, 770, 775, 777, 779, 784, 785, 786, 787, 792], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectkbest.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Multinomial Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a Multinomial Naive Bayes Classifier, which is frequently used in Tf-idf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "mnb = MultinomialNB()\n",
    "# train the model using training set \n",
    "mnb.fit(X_train_vec2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Log Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>-3.363170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adobe</th>\n",
       "      <td>-4.003011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>-4.063951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>-4.216826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>software</th>\n",
       "      <td>-4.471718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>php</th>\n",
       "      <td>-4.493850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suite</th>\n",
       "      <td>-4.545826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft</th>\n",
       "      <td>-4.569681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2007</th>\n",
       "      <td>-4.574777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>-4.643496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>office</th>\n",
       "      <td>-4.729140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mac</th>\n",
       "      <td>-4.779571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>acrobat</th>\n",
       "      <td>-4.793778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>size</th>\n",
       "      <td>-4.852715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>availability</th>\n",
       "      <td>-4.885280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>-4.895788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deliver</th>\n",
       "      <td>-4.937124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investment</th>\n",
       "      <td>-4.950051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>money</th>\n",
       "      <td>-4.953775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>opinion</th>\n",
       "      <td>-4.970709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>-4.972608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>www</th>\n",
       "      <td>-4.999585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broker</th>\n",
       "      <td>-5.001540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shares</th>\n",
       "      <td>-5.003499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>broadband</th>\n",
       "      <td>-5.013351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offers</th>\n",
       "      <td>-5.031334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>offer</th>\n",
       "      <td>-5.072492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>save</th>\n",
       "      <td>-5.122017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pay</th>\n",
       "      <td>-5.128662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creative</th>\n",
       "      <td>-5.153410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pro</th>\n",
       "      <td>-5.171801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-5.214462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>-5.219316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>download</th>\n",
       "      <td>-5.236495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macromedia</th>\n",
       "      <td>-5.238973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drive</th>\n",
       "      <td>-5.246445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-5.264100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>instantly</th>\n",
       "      <td>-5.269202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vista</th>\n",
       "      <td>-5.271763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reviews</th>\n",
       "      <td>-5.276904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>enterprise</th>\n",
       "      <td>-5.279485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95your</th>\n",
       "      <td>-5.289875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49adobe</th>\n",
       "      <td>-5.305664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>product</th>\n",
       "      <td>-5.329827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>special</th>\n",
       "      <td>-5.346265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>roof</th>\n",
       "      <td>-5.374278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cs2</th>\n",
       "      <td>-5.377123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uwaterloo</th>\n",
       "      <td>-5.403099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pr0</th>\n",
       "      <td>-5.403099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technologies</th>\n",
       "      <td>-5.485337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Log Probability\n",
       "com                 -3.363170\n",
       "adobe               -4.003011\n",
       "79                  -4.063951\n",
       "price               -4.216826\n",
       "software            -4.471718\n",
       "php                 -4.493850\n",
       "suite               -4.545826\n",
       "microsoft           -4.569681\n",
       "2007                -4.574777\n",
       "59                  -4.643496\n",
       "office              -4.729140\n",
       "mac                 -4.779571\n",
       "acrobat             -4.793778\n",
       "size                -4.852715\n",
       "availability        -4.885280\n",
       "use                 -4.895788\n",
       "deliver             -4.937124\n",
       "investment          -4.950051\n",
       "money               -4.953775\n",
       "opinion             -4.970709\n",
       "power               -4.972608\n",
       "www                 -4.999585\n",
       "broker              -5.001540\n",
       "shares              -5.003499\n",
       "broadband           -5.013351\n",
       "offers              -5.031334\n",
       "offer               -5.072492\n",
       "save                -5.122017\n",
       "pay                 -5.128662\n",
       "creative            -5.153410\n",
       "pro                 -5.171801\n",
       "49                  -5.214462\n",
       "like                -5.219316\n",
       "download            -5.236495\n",
       "macromedia          -5.238973\n",
       "drive               -5.246445\n",
       "80                  -5.264100\n",
       "instantly           -5.269202\n",
       "vista               -5.271763\n",
       "reviews             -5.276904\n",
       "enterprise          -5.279485\n",
       "95your              -5.289875\n",
       "49adobe             -5.305664\n",
       "product             -5.329827\n",
       "special             -5.346265\n",
       "roof                -5.374278\n",
       "cs2                 -5.377123\n",
       "uwaterloo           -5.403099\n",
       "pr0                 -5.403099\n",
       "technologies        -5.485337"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Empirical log probability of features given a class 1 (spam)\n",
    "coeff_df = pd.DataFrame(mnb.feature_log_prob_[1,:].flatten(), [vectorizer.get_feature_names_out()[i] for i in selectkbest.get_support(indices=True)], columns=['Log Probability'])  \n",
    "coeff_df = coeff_df.sort_values(by=['Log Probability'], ascending=False)\n",
    "\n",
    "# display the 50 most informative features (indicate spam)\n",
    "coeff_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class prediction for test set\n",
    "# y_pred_class is the binary label\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict\n",
    "y_pred_class = mnb.predict(X_test_vec2)\n",
    "\n",
    "# y_pred_prob is the probability estimate\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict_proba\n",
    "y_pred_prob = mnb.predict_proba(X_test_vec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9116317303740238\n",
      "Confusion Matrix: [[1463    8]\n",
      " [ 207  755]]\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93      1471\n",
      "           1       0.99      0.78      0.88       962\n",
      "\n",
      "    accuracy                           0.91      2433\n",
      "   macro avg       0.93      0.89      0.90      2433\n",
      "weighted avg       0.92      0.91      0.91      2433\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_class, normalize=True, sample_weight=None))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_pred_class))\n",
    "print(\"Classification Report:\",classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Import Multinomial Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a Multinomial Naive Bayes Classifier, which is frequently used in Tf-idf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "mnb = MultinomialNB()\n",
    "\n",
    "sfs = SequentialFeatureSelector(mnb,  \n",
    "           n_features_to_select=400,\n",
    "           direction='forward',\n",
    "           scoring='accuracy',\n",
    "           cv=4)\n",
    "\n",
    "sfs.fit(X_train_vec, y_train) \n",
    "X_train_vec3 = sfs.transform(X_train_vec)\n",
    "X_test_vec3 = sfs.transform(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.get_support(indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Multinomial Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a Multinomial Naive Bayes Classifier, which is frequently used in Tf-idf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "mnb = MultinomialNB()\n",
    "# train the model using training set \n",
    "mnb.fit(X_train_vec3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empirical log probability of features given a class 1 (spam)\n",
    "coeff_df = pd.DataFrame(mnb.feature_log_prob_[1,:].flatten(), [vectorizer.get_feature_names_out()[i] for i in selectkbest.get_support(indices=True)], columns=['Log Probability'])  \n",
    "coeff_df = coeff_df.sort_values(by=['Log Probability'], ascending=False)\n",
    "\n",
    "# display the 50 most informative features (indicate spam)\n",
    "coeff_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class prediction for test set\n",
    "# y_pred_class is the binary label\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict\n",
    "y_pred_class = mnb.predict(X_test_vec3)\n",
    "\n",
    "# y_pred_prob is the probability estimate\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict_proba\n",
    "y_pred_prob = mnb.predict_proba(X_test_vec3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_class, normalize=True, sample_weight=None))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_pred_class))\n",
    "print(\"Classification Report:\",classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_vec, y_train)\n",
    "lr.coef_\n",
    "selector = SelectFromModel(lr, prefit=True,max_features=400,threshold=-np.inf)\n",
    "X_train_vec4 = selector.transform(X_train_vec)\n",
    "X_test_vec4 = selector.transform(X_test_vec)\n",
    "X_train_vec4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Multinomial Naive Bayes model from sklearn\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Create a Multinomial Naive Bayes Classifier, which is frequently used in Tf-idf\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html\n",
    "mnb = MultinomialNB()\n",
    "# train the model using training set \n",
    "mnb.fit(X_train_vec4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Empirical log probability of features given a class 1 (spam)\n",
    "coeff_df = pd.DataFrame(mnb.feature_log_prob_[1,:].flatten(), [vectorizer.get_feature_names_out()[i] for i in selector.get_support(indices=True)], columns=['Log Probability'])  \n",
    "coeff_df = coeff_df.sort_values(by=['Log Probability'], ascending=False)\n",
    "\n",
    "# display the 50 most informative features (indicate spam)\n",
    "coeff_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make class prediction for test set\n",
    "# y_pred_class is the binary label\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict\n",
    "y_pred_class = mnb.predict(X_test_vec4)\n",
    "\n",
    "# y_pred_prob is the probability estimate\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB.predict_proba\n",
    "y_pred_prob = mnb.predict_proba(X_test_vec4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",accuracy_score(y_test, y_pred_class, normalize=True, sample_weight=None))\n",
    "print(\"Confusion Matrix:\", confusion_matrix(y_test, y_pred_class))\n",
    "print(\"Classification Report:\",classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
